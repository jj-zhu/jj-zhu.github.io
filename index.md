---
layout: page
published: true
---
![jjzhu](/images/jzhu-photo.jpg){:style="float: right;margin-right: 14px;margin-right: 7px;margin-top: 7px;width: 320px;display: block"}
I am the head of an independent research group at the [Weierstrass Institute for Applied Analysis and Stochastics, Berlin](https://www.wias-berlin.de/).
Prior to Berlin, I worked as a postdoctoral researcher in machine learning at the Max Planck Institute for Intelligent Systems in Tübingen, Germany. My Ph.D. study was in numerical optimization, at the University of Florida. See [here](/about/) for a short bio. 
I also write [a non-research blog here](https://jj-zhu.github.io/blog/). Though the frequency of updates depends on how busy I am at the moment.

My group focuses on research in state-of-the-art machine learning and optimization, in algorithm, theory, and large-scale computation.
Specifically, I started my research career in numerical optimization, and was interested in the robustness theory for machine learning. That requires us to use computational tools such as **optimization algorithms over probability distributions**, which are infinite-dimensional. That led me to my current interests in **(PDE) gradient flows of probability measures and variational approach to dynamical systems**, for optimization and computational machine learning.

For example, in some of my previous works, I invented [robust learning algorithms that can protect against distribution shifts using principled kernel methods](https://arxiv.org/pdf/2006.06981.pdf).
Those optimization algorithms in fact have deep theoretical roots in dynamical system theory such as PDEs.
Following that and after moving to Berlin, I dedicate my current research to *interfacing large-scale computational algorithms in machine learning/optimization with dynamical systems theory such as (PDE) gradient flows and optimal transport*.

To get in touch, click the icon at the bottom of the page.

[New] We have a **postdoc position opening** in Berlin, in the intersection between (reduced-order) data-driven PDE dynamics modeling for medical imaging, and machine learning. Please contact if you are interested and have relevant background in PDE/numerical analysis/medical imaging.

### News and updates
- I am teaching the [nonparametric statistics course at Humboldt University of Berlin (at master level)](https://agnes.hu-berlin.de/lupo/rds?state=verpublish&status=init&vmfile=no&publishid=207589&moduleCall=webInfo&publishConfFile=webInfo&publishSubDir=veranstaltung), co-lecturing with Vladimir Spokoinyi, in term 2023/24. More information coming soon.
- I talked about the gradient flow force-balance, especially in robust learning under (strong) structured distribution shifts, and conditional moment restriction for causal inference at [EUCCO 2023](https://scoop.iwr.uni-heidelberg.de/events/2023_eucco/), at Heidelberg University. [Talk slides available](https://jj-zhu.github.io/file/Heidelberg-EUCCO-2023-Zhu.pdf)
- I'm organizing a [Workshop on Optimal Transport from Theory to Applications – Interfacing Dynamical Systems, Optimization, and Machine Learning](https://sites.google.com/view/
ot-berlin-2024) (OT-DOM) in Berlin, Germany. March 11th - 15th, 2024. More information coming soon.
- I taught a mini-course on the optimization perspective of gradient flow dynamics, introducing (beginner-friendly) concepts of gradient flows in the Eulidean and Wasserstein space, at the [Workshop of Intelligent Autonomous Learning Systems 2023](https://www.ias.informatik.tu-darmstadt.de/Workshops/IWIALS2023). Lecture slides available:  
  - [slides for the mini-course](https://jj-zhu.github.io/file/IWIAS-mini-course-opt-gf-aug-2023-nopause.pdf)
  - [slides for the introduction to our research](https://jj-zhu.github.io/file/IWIAS-2023-intro-zhu.pdf)
- July 2023. I gave an invited talk at the [ICML 2023 Workshop on Duality Principles for Modern Machine Learning](https://dp4ml.github.io/). The slides are available [here](https://jj-zhu.github.io/file/duality-ICML-2023-Zhu.pdf).
- July 2023. Accepted paper at CDC 2023: [Propagating Kernel Ambiguity Sets in Nonlinear Data-driven Dynamics Models](https://arxiv.org/abs/2304.14057)
    - In this paper, I discovered the ambiguity set and geometric structure that can be propagated in nonlinear data-driven dynamics models. This is the first algorithm that can quantify the uncertainty of uncertainty -- the ambiguity of data-driven Koopman operators and kernel conditional mean embedding models.
- June 2023. Heiner Kremer and Yassine Nemmour gave talks on their works in kernel methods and DRO at the Mini-Symposiums at the SIAM Conference on Optimization 2023 in Seattle, Washington.
- May 2023. Accepted paper at ICML 2023 [(link to preprint)](https://arxiv.org/abs/2305.10898): Heiner Kremer, Yassine Nemmour, Bernhard Sch ̈olkopf, and Jia-Jie Zhu. Estimation Beyond Data Reweighting: Kernel Method of Moments.
- May 2023. A couple of new preprints are available:
    - [Nonlinear Wasserstein Distributionally Robust Optimal Control](https://arxiv.org/abs/2304.07415)
    - [Propagating Kernel Ambiguity Sets in Nonlinear Data-driven Dynamics Models](https://arxiv.org/abs/2304.14057)
- Apr 2023. Gave a plenary talk at the Leibniz Institute for Agricultural Engineering and Bioeconomy Potsdam, during the workshop "Mathematical Modeling and Simulation" (MMS) Days.
- Served as area chair for AISTATS 2023.  
- Sep 2022. [Here are the slides](https://jj-zhu.github.io/file/Eindhoven-OT-workshop-2022-Zhu.pdf) for a recent talk I gave at the OT workshop at TU Eindhoven.

#### Twitter feed
<a class="twitter-timeline" data-width="800" href="https://twitter.com/__jzhu__?ref_src=twsrc%5Etfw">Tweets by __jzhu__</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


